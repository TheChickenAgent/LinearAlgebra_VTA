{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f3f42e",
   "metadata": {},
   "source": [
    "# OpenAI notebook\n",
    "\n",
    "| Pedagogy Dimension | Metrics |\n",
    "| --- | ----------- |\n",
    "| Manage cognitive load | Stay on topic |\n",
    "| Encourage active learning | Do not reveal the answer; guide towards the answer; promote active engagement |\n",
    "| Deepen metacognition | Identify and address misconceptions |\n",
    "| Motivate and stimulate curiosity | Communicate with positive tone; respond appropriately to explicit affect cues |\n",
    "| Adapt to the learners’ goals and needs | Adapt to the learner’s level |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15f9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "DATA_DIR = \"user-testing/data/\"\n",
    "\n",
    "def list_pickle_files(directory):\n",
    "    return [f for f in os.listdir(directory) if f.endswith('.pkl')]\n",
    "\n",
    "def load_conversation(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "def read_questions_answers():\n",
    "    # Split out True/False questions\n",
    "    exam_questions_TF = []\n",
    "    exam_answers_TF = []\n",
    "\n",
    "    with open('exams/together2.tex', 'r', encoding='utf-8') as file:\n",
    "        tex_content = file.read()\n",
    "        questions, answers = extract_question_answer(tex_content)\n",
    "        #print(f\"Total Questions: {len(questions)}\")\n",
    "        #print(f\"Total Answers: {len(answers)}\")\n",
    "        if len(questions) != len(answers):\n",
    "            print(\"Warning: The number of questions and answers do not match!\")\n",
    " \n",
    "        #print()\n",
    "        for idx, (q, a) in enumerate(zip(questions, answers), 1):\n",
    "            #print(f\"Question {idx}:\\n{q}\\n\")\n",
    "            #print(f\"Answer {idx}:\\n{a}\\n\")\n",
    "            exam_questions_TF.append(q)\n",
    "            exam_answers_TF.append(a)\n",
    "    return exam_questions_TF, exam_answers_TF\n",
    "\n",
    "def extract_question_answer(tex_content):\n",
    "    # Extract content within the enumerate environment\n",
    "    enum_match = re.search(r'\\\\begin{enumerate}(.*?)\\\\end{enumerate}', tex_content, re.DOTALL)\n",
    "    if not enum_match:\n",
    "        return [], []\n",
    "    enum_content = enum_match.group(1)\n",
    "\n",
    "    # Find all questions (\\item ... \\begin{solutionorbox})\n",
    "    question_blocks = re.findall(\n",
    "        r'\\\\item(.*?)(?=\\\\begin{solutionorbox})',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "\n",
    "    # Find all answers (\\begin{solutionorbox} ... \\end{solutionorbox})\n",
    "    answer_blocks = re.findall(\n",
    "        r'\\\\begin{solutionorbox}\\[[^\\]]*\\]\\s*(.*?)\\\\end{solutionorbox}',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "    questions = [q.strip() for q in question_blocks]\n",
    "    answers = [a.strip() for a in answer_blocks]\n",
    "    return questions, answers\n",
    "\n",
    "def remove_latex_formatting(question: str) -> str:\n",
    "    # Remove LaTeX bold formatting\n",
    "    question = question.replace(\"\\\\textbf{always}\", \"*always*\")  \n",
    "    question = question.replace(\"\\\\textbf{Every}\", \"*Every*\")\n",
    "    question = question.replace(\"\\\\textbf{any}\", \"*any*\")\n",
    "    question = question.replace(\"\\\\textbf{rotation}\", \"*rotation*\")\n",
    "    question = question.replace(\"\\\\textbf{distinct}\", \"*distinct*\")\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "OPENAI_API = os.getenv('OPENAI_API_KEY')\n",
    "llm = OpenAI(api_key=OPENAI_API)\n",
    "openai_model = \"o4-mini\"\n",
    "\n",
    "o4_llm_state = pickle.load(open('exams/together2_llm_state.pkl', 'rb'))\n",
    "exam_questions_TF, exam_answers_TF = read_questions_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafa5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_summary = \"\"\"\n",
    "You are an AI assistant that summarizes conversations between a Student and a Tutor AI model.\n",
    "Your task is to analyze the conversation and provide a summary of the student's main difficulties.\n",
    "You are not responsible for providing answers to the questions, but rather to identify the key areas where the student struggled or needed help.\n",
    "You will be given a conversation in the form of a list of messages, where each message is\n",
    "a dictionary with 'role' (either 'user' or 'assistant') and 'content' (the text of the message).\n",
    "Your summary should be concise and focus on the student's challenges, misconceptions, or areas of confusion.\n",
    "***The conversation:***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f669a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_summary = \"\"\"\n",
    "You are an AI assistant that merges the difficulties that students had during a conversation with a Tutor AI model.\n",
    "You will be given a string with all the difficulties for the same (fixed) question.\n",
    "Your task is to summarize/merge the different difficulties that students had during the conversation and provide a summary of the student's main difficulties.\n",
    "Your summary should be concise and focus on the student's challenges, misconceptions, or areas of confusion.\n",
    "***All difficulties:***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b830f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary = \"\"\"\n",
    "You are an AI assistant that merges the difficulties that students had during a conversation with a Tutor AI model.\n",
    "You will be given a string with all the difficulties for different questions.\n",
    "Your task is to summarize/merge the different difficulties that students had during the conversation and provide a summary of the student's main difficulties.\n",
    "Your summary should be concise and focus on the student's challenges, misconceptions, or areas of confusion.\n",
    "***All difficulties over different questions:***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe0b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_role_prefix_to_conversation(conversation):\n",
    "    \"\"\"\n",
    "    Returns a new conversation list where each message's content is prefixed\n",
    "    with 'Student:' or 'Tutor:' depending on the role.\n",
    "\n",
    "    Args:\n",
    "        conversation (list): List of dicts with 'role' and 'content'.\n",
    "\n",
    "    Returns:\n",
    "        list: New conversation list with prefixed content.\n",
    "    \"\"\"\n",
    "    role_prefix = {'user': 'Student:', 'assistant': 'Tutor:'}\n",
    "    new_conversation = []\n",
    "    for msg in conversation:\n",
    "        prefix = role_prefix.get(msg['role'], '')\n",
    "        new_content = f\"{prefix} {msg['content'].strip()}\"\n",
    "        new_conversation.append({'role': msg['role'], 'content': new_content})\n",
    "    return new_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45005dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt: str, messages:list|str, openai_model=\"o4-mini\"):\n",
    "    \"\"\"\n",
    "    Query the LLM with the given prompt and messages.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the LLM.\n",
    "        messages (list): List of messages in the conversation.\n",
    "        openai_model (str): The OpenAI model to use for the query.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the LLM.\n",
    "    \"\"\"\n",
    "    new_messages = []\n",
    "    if isinstance(messages, list):\n",
    "        new_messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "\n",
    "        for msg in messages:\n",
    "            new_messages.append({\n",
    "                \"role\": msg[\"role\"],\n",
    "                \"content\": msg[\"content\"]\n",
    "            })\n",
    "    elif isinstance(messages, str):\n",
    "        new_messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "        new_messages.append({\"role\": \"user\", \"content\": messages})\n",
    "    new_messages.append({\"role\": \"system\", \"content\": \"Request: perform your task.\"})\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=new_messages,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c7df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_ideas(openai_model=\"o4-mini\"):\n",
    "    files_questions = {}\n",
    "    for filename in list_pickle_files(DATA_DIR):\n",
    "        filepath = os.path.join(DATA_DIR, filename)\n",
    "        conversation_data = load_conversation(filepath)\n",
    "\n",
    "        # Get the selected question\n",
    "        selected_question = int(conversation_data[\"selected_question\"].strip(\"Q\")) - 1\n",
    "\n",
    "        # Store it in the dictionary\n",
    "        if selected_question in files_questions:\n",
    "            files_questions[selected_question].append(filepath)\n",
    "        else:\n",
    "            files_questions[selected_question] = [filepath]\n",
    "            \n",
    "\n",
    "    # Now, we can process each question with its associated files\n",
    "    recommendations_per_file = {}\n",
    "    for selected_question, files in tqdm(files_questions.items()):\n",
    "        for file in tqdm(files):\n",
    "            conversation_data = load_conversation(file)\n",
    "            conversation = conversation_data[\"messages\"]\n",
    "            student_tutor_conversations = add_role_prefix_to_conversation(conversation)\n",
    "\n",
    "            # Use LLM to get recommendations for each conversation\n",
    "            recommendation = query_llm(conversation_summary, student_tutor_conversations, openai_model=openai_model)\n",
    "\n",
    "            # Store it in the dictionary\n",
    "            if selected_question in recommendations_per_file:\n",
    "                recommendations_per_file[selected_question].append(recommendation)\n",
    "            else:\n",
    "                recommendations_per_file[selected_question] = [recommendation]\n",
    "\n",
    "    # Merge the recommendations into a single list per question\n",
    "    recommendations_per_question = {}\n",
    "    for selected_question in tqdm(recommendations_per_file.keys()):\n",
    "        recommendations = recommendations_per_file[selected_question]\n",
    "        merged_recommendation = \"\\n\\n\".join(recommendations)\n",
    "\n",
    "        # Use LLM to get merged recommendation for each question.\n",
    "        merged_recommendation = query_llm(question_summary, merged_recommendation, openai_model=openai_model)\n",
    "\n",
    "        recommendations_per_question[selected_question] = merged_recommendation\n",
    "    \n",
    "    # Get overall recommendations\n",
    "    merged_overall_recommendations = \" \".join(recommendations_per_question.values())\n",
    "    # Use LLM to get overall recommendations\n",
    "    overall_recommendations = query_llm(overall_summary, merged_overall_recommendations, openai_model=openai_model)\n",
    "\n",
    "    return recommendations_per_file, recommendations_per_question, overall_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6376bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommendations_per_file, recommendations_per_question, overall_recommendations = get_report_ideas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "366f9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_questions = {}\n",
    "for filename in list_pickle_files(DATA_DIR):\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    conversation_data = load_conversation(filepath)\n",
    "\n",
    "    # Get the selected question\n",
    "    selected_question = int(conversation_data[\"selected_question\"].strip(\"Q\")) - 1\n",
    "\n",
    "    # Store it in the dictionary\n",
    "    if selected_question in files_questions:\n",
    "        files_questions[selected_question].append(filepath)\n",
    "    else:\n",
    "        files_questions[selected_question] = [filepath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58e7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.13s/it]\n",
      "100%|██████████| 6/6 [00:29<00:00,  4.90s/it]\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.18s/it]\n",
      "100%|██████████| 6/6 [00:29<00:00,  4.84s/it]\n",
      "100%|██████████| 10/10 [00:43<00:00,  4.32s/it]\n",
      "100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.86s/it]\n",
      "100%|██████████| 7/7 [02:40<00:00, 22.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Now, we can process each question with its associated files\n",
    "recommendations_per_file = {}\n",
    "for selected_question, files in tqdm(files_questions.items()):\n",
    "    for file in tqdm(files):\n",
    "        conversation_data = load_conversation(file)\n",
    "        conversation = conversation_data[\"messages\"]\n",
    "        student_tutor_conversations = add_role_prefix_to_conversation(conversation)\n",
    "\n",
    "        # Use LLM to get recommendations for each conversation\n",
    "        recommendation = query_llm(conversation_summary, student_tutor_conversations, openai_model=openai_model)\n",
    "\n",
    "        # Store it in the dictionary\n",
    "        if selected_question in recommendations_per_file:\n",
    "            recommendations_per_file[selected_question].append(recommendation)\n",
    "        else:\n",
    "            recommendations_per_file[selected_question] = [recommendation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8c8a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:39<00:00,  5.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Merge the recommendations into a single list per question\n",
    "recommendations_per_question = {}\n",
    "for selected_question in tqdm(recommendations_per_file.keys()):\n",
    "    recommendations = recommendations_per_file[selected_question]\n",
    "    merged_recommendation = \"\\n\\n\".join(recommendations)\n",
    "\n",
    "    # Use LLM to get merged recommendation for each question.\n",
    "    merged_recommendation = query_llm(question_summary, merged_recommendation, openai_model=openai_model)\n",
    "\n",
    "    recommendations_per_question[selected_question] = merged_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cfc4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overall recommendations\n",
    "merged_overall_recommendations = \" \".join(recommendations_per_question.values())\n",
    "# Use LLM to get overall recommendations\n",
    "overall_recommendations = query_llm(overall_summary, merged_overall_recommendations, openai_model=openai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd7620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recommendations_per_file.pkl', 'wb') as f:\n",
    "    pickle.dump(recommendations_per_file, f)\n",
    "\n",
    "with open('recommendations_per_question.pkl', 'wb') as f:\n",
    "    pickle.dump(recommendations_per_question, f)\n",
    "\n",
    "with open('overall_recommendations.pkl', 'wb') as f:\n",
    "    pickle.dump(overall_recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe1eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('recommendations_per_file.pkl', 'rb') as f:\n",
    "    recommendations_per_file = pickle.load(f)\n",
    "\n",
    "with open('recommendations_per_question.pkl', 'rb') as f:\n",
    "    recommendations_per_question = pickle.load(f)\n",
    "\n",
    "with open('overall_recommendations.pkl', 'rb') as f:\n",
    "    overall_recommendations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f6bb1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'The student’s difficulties can be grouped into three main areas:\\n\\n1. Notation and basic concepts  \\n   - Misreading “{u, v}” as a system of equations rather than the set containing two vectors.  \\n   - Unclear that independence/dependence is a property of a set of vectors, not of an individual vector or matrix.\\n\\n2. Formal definition vs. intuition  \\n   - Forgotten or confused the precise criterion: “a set is independent iff the only solution to c₁v₁ + … + cₖvₖ = 0 is the trivial one (all cᵢ = 0).”  \\n   - Initially equated dependence only with one vector being a scalar multiple of another, rather than any nontrivial linear combination.\\n\\n3. Applying the definition  \\n   - Struggled to translate v₁c₁ + v₂c₂ = 0 into componentwise equations and solve for c₁, c₂.  \\n   - Misremembered given relations (e.g. accidentally introduced u + v = 0).  \\n   - Didn’t immediately see that a free variable in the three‐vector test implies infinitely many nontrivial solutions—and thus dependence.',\n",
       " 1: 'The student’s main challenges clustered around three areas:\\n\\n1.  Conceptual Foundations  \\n    - Lacking a crisp definition of an orthogonal matrix (MᵀM = I or equivalently M⁻¹ = Mᵀ), and confusing that with the notion of orthogonal vectors.  \\n    - Uncertainty about what a transpose is, what the identity matrix I is, and how matrix multiplication works.  \\n\\n2.  Key Algebraic Properties  \\n    - Applying the product–transpose rule (AB)ᵀ = BᵀAᵀ.  \\n    - Seeing why, in (AB)ᵀ(AB) = Bᵀ(AᵀA)B = BᵀB = I, both A and B being orthogonal force AB to be orthogonal.  \\n\\n3.  Application & Reasoning  \\n    - Working through concrete examples (e.g. showing the zero matrix fails MᵀM = I).  \\n    - Interpreting “relation” among columns in terms of linear dependence and how dependence in B’s columns carries over to AB.  \\n    - Performing the actual matrix multiplications without arithmetic slips.  \\n    - Articulating each logical step instead of jumping to “false” or accepting statements without justification.',\n",
       " 2: 'The student’s difficulties cluster around two broad areas—basic eigen‐concepts and the algebraic machinery used to derive the characteristic equation (and then extend it to Aᵀ):\\n\\n1. Misunderstanding of eigenvalues vs. eigenvectors  \\n   - Could not clearly state or interpret A v = λ v  \\n   - Confused eigenvectors (the nonzero v) with eigenvalues (the scalars λ)  \\n\\n2. Scalar-vs-matrix operations  \\n   - Didn’t see why λ becomes λ I when mixing scalars and matrices  \\n   - Mixed up left/right multiplication ((λ I)v vs. v(λ I))  \\n\\n3. Rearranging and factoring to get (A − λ I)v = 0  \\n   - Struggled to move terms, factor out v, and recognize the zero‐vector condition  \\n\\n4. Link between det(A − λ I)=0 and nontrivial solutions  \\n   - Didn’t grasp that a zero determinant means non‐invertibility, which in turn allows nonzero v  \\n\\n5. Transpose operation and its determinant  \\n   - Unfamiliar with (AB)ᵀ = BᵀAᵀ and the fact that det(Aᵀ)=det(A)  \\n   - Unsure how to show A and Aᵀ share the same eigenvalues without inventing a new “transpose” eigenvector  \\n\\nIn short, the student needs a firm review of (1) what eigenvalues/eigenvectors are, (2) how λ I and determinants produce the characteristic polynomial, and (3) how transposes interact with determinants and matrix‐vector products.',\n",
       " 3: 'The student’s conceptual roadblocks boil down to three interrelated gaps:\\n\\n1. Foundations of symmetry  \\n   - They haven’t firmly grasped the definition “A is symmetric ⇔ Aᵀ = A,” nor why that forces aᵢⱼ = aⱼᵢ.  \\n   - They’re unsure what, if any, constraints symmetry places on diagonal entries.\\n\\n2. Transpose‐and‐product mechanics  \\n   - They don’t see how (AB)ᵀ = BᵀAᵀ combines with Aᵀ = A, Bᵀ = B to yield AB = BA as the only way to make (AB)ᵀ = AB.  \\n   - They’re unclear why two individually symmetric factors can fail to produce a symmetric product unless they commute.\\n\\n3. Concrete examples and notation  \\n   - They need non-trivial examples of symmetric matrices (beyond “all-ones”) to get intuition.  \\n   - They struggle to translate symmetry into index form (aᵢⱼ = aⱼᵢ) and to check off-diagonal entries in practice.\\n\\nIn sum, the student needs:  \\n• A clear definition and consequences of symmetry (including diagonal vs. off-diagonal behavior)  \\n• Step-by-step application of the transpose rule to AB  \\n• Illustrative examples showing when AB ≠ BA spoils symmetry  \\n• Practice with index notation to link the abstract identities to entrywise checks.',\n",
       " 5: 'The student’s difficulties can be grouped into two broad, interrelated areas:\\n\\n1. Fundamentals of the dot product and orthogonality  \\n   • They didn’t consistently carry out the dot-product procedure: they stopped at pairwise multiplications and sometimes thought the result was a vector instead of summing to a scalar.  \\n   • They forgot that orthogonality means a dot product of zero (initially guessed “positive value”).  \\n   • They were unclear on what an “orthogonal set” entails—namely, that you must check every pair in a collection of vectors (there are n(n–1)/2 pairs) and confirm each dot product vanishes.  \\n\\n2. Structure and interpretation of the 2×2 rotation matrix  \\n   • They weren’t sure why its entries are exactly [cos θ  –sin θ;  sin θ  cos θ], nor how cos θ and sin θ arise from rotating basis vectors by angle θ.  \\n   • They struggled to see how plugging in a specific angle (e.g. 90°) changes those entries and why the matrix’s columns remain orthonormal.  \\n   • They held the misconception that a “rotation matrix” must look identical after certain rotations, rather than understanding that its components vary continuously with θ.  \\n   • They needed help linking the geometric action (rotating (1,0) and (0,1)) to the algebraic form and verifying orthogonality of the resulting column vectors via the dot product.',\n",
       " 6: 'The student’s main challenges can be grouped into five areas:\\n\\n1. Definitions and concrete meaning of symmetry  \\n   – Precisely recalling that “A is symmetric” means A = Aᵀ (equivalently aᵢⱼ = aⱼᵢ) rather than just “rows look like columns.”  \\n   – Seeing how this plays out in a simple 2×2 example (e.g. a₁₂ = a₂₁).\\n\\n2. Applying the transpose-of-a-product rule  \\n   – Remembering (XYZ)ᵀ = Zᵀ\\u2009Yᵀ\\u2009Xᵀ in a multi-factor product.  \\n   – Choosing how to group factors (e.g. treating BᵀA as one block) and tracking the reversal of order.  \\n   – Handling double transposes ((Bᵀ)ᵀ = B) to simplify the expression.\\n\\n3. Step-by-step algebraic execution  \\n   – Writing out each intermediate transpose and substitution instead of leaping to the final result.  \\n   – Organizing the work so that one can clearly see (Bᵀ\\u2009A\\u2009B)ᵀ → Bᵀ\\u2009Aᵀ\\u2009(Bᵀ)ᵀ → Bᵀ\\u2009A\\u2009B.\\n\\n4. Basic matrix-multiplication conventions and misconceptions  \\n   – Ensuring dimensions match (columns of one matrix = rows of the next) and identifying the correct size of a product (m×q for an m×n times n×q).  \\n   – Avoiding the false leap from “symmetric” (and square) straight to “identity,” and clarifying which matrices in the problem must be tested for which properties.\\n\\n5. Articulation of understanding  \\n   – Restating definitions and properties in their own words when prompted.  \\n   – Connecting each algebraic step back to the core concept (showing Mᵀ = M is exactly what it means to be symmetric).',\n",
       " 7: 'The student’s core challenges revolved around the fine points of orthogonality versus linear independence:  \\n• They had not internalized that an orthogonal set must consist of *distinct nonzero* vectors whose pairwise inner products vanish.  \\n• They missed that the standard result “orthogonal ⇒ linearly independent” only holds when no vector in the set is the zero vector.  \\n• They were puzzled by the fact that the zero vector is orthogonal to every vector (its inner product is zero) yet its inclusion automatically creates a linear dependency.  \\n• As a result, they needed help seeing how the simple counterexample {0, e₁} illustrates that an “orthogonal” set containing 0 can fail to be independent.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_recommendations_per_question = dict(sorted(recommendations_per_question.items()))\n",
    "sorted_recommendations_per_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0fb404f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "def generate_lecturer_report_pdf():\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.add_font(\"DejaVu\", \"\", \"fonts\\\\DejaVuSans.ttf\", uni=True)\n",
    "    pdf.add_font(\"DejaVu\", \"B\", \"fonts\\\\DejaVuSans-Bold.ttf\", uni=True)\n",
    "    pdf.add_font(\"DejaVu\", \"BI\", \"fonts\\\\DejaVuSans-BoldOblique.ttf\", uni=True)\n",
    "\n",
    "    pdf.set_font(\"DejaVu\", \"BI\", size=18)\n",
    "    pdf.cell(0, 10, \"Lecturer Report Tutorial Questions\", ln=True)\n",
    "\n",
    "    pdf.set_font(\"DejaVu\", \"B\", size=14)\n",
    "    pdf.cell(0, 10, \"General statistics\", ln=True)\n",
    "\n",
    "    #Calculate statistics\n",
    "    pdf.set_font(\"DejaVu\", size=10)\n",
    "    # number of students (might not be exactly the same as number of conversations, but we do not have a unique identifier for students)\n",
    "    num_conversations = sum(len(v) for v in recommendations_per_file.values())\n",
    "    pdf.cell(0, 10, f\"- Number of conversations: {num_conversations}\", ln=True)\n",
    "    # number of questions\n",
    "    num_questions = len(recommendations_per_question.keys())\n",
    "    pdf.cell(0, 10, f\"- Number of questions in this tutorial: {num_questions}\", ln=True)\n",
    "    pdf.cell(0, 10, \"\", ln=True)  # Add a blank line for spacing\n",
    "\n",
    "    pdf.set_font(\"DejaVu\", \"B\", size=14)\n",
    "    pdf.cell(0, 10, \"Overall insights\", ln=True)\n",
    "    pdf.set_font(\"DejaVu\", size=10)\n",
    "    #pdf.multi_cell(0, 10, \"This section contains insights generated by AI that has analysed the conversation that students had with the system.\")\n",
    "    # Insert overall recommendations\n",
    "    pdf.multi_cell(0, 10, overall_recommendations)\n",
    "    pdf.cell(0, 10, \"\", ln=True)  # Add a blank line for spacing\n",
    "\n",
    "    # Insert question-specific recommendations\n",
    "    pdf.set_font(\"DejaVu\", \"B\", size=14)\n",
    "    pdf.cell(0, 10, \"Question-specific insights\", ln=True)\n",
    "    for question, recommendations in sorted_recommendations_per_question.items():\n",
    "        pdf.set_font(\"DejaVu\", \"B\", size=10)\n",
    "        pdf.cell(0, 10, f\"Question {question+1}\", ln=True)\n",
    "        pdf.set_font(\"DejaVu\", size=10)\n",
    "        pdf.multi_cell(0, 10, recommendations)\n",
    "        pdf.cell(0, 10, \"\", ln=True)  # Add a blank line for spacing\n",
    "    #pdf.multi_cell(0, 10, \"This section contains insights generated by AI that has analysed the conversation that students had with the system.\")\n",
    "\n",
    "    # Get PDF as bytes\n",
    "    pdf.output(name='Lecturer Report.pdf')\n",
    "    return pdf\n",
    "pdf_bytes = generate_lecturer_report_pdf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
