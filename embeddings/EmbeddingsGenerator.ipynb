{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6872720",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edac0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0bccc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc33a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 topics are:\n",
      "Systems of linear equations, Gaussian elimination\n",
      "-Vector equations, Matrix\n",
      "-Solution sets and Linear independence\n",
      "-Linear Transformations, Matrix algebra\n",
      "-The Inverse of a Matrix\n",
      "-Determinants, Perspective projections\n",
      "-Vector Spaces\n",
      "-Eigenvalues and Eigenvectors\n",
      "-Diagonalization\n",
      "-Orthogonality and Symmetric Matrices\n"
     ]
    }
   ],
   "source": [
    "def load_json(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load the JSON file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): name of the file to load\n",
    "\n",
    "    Returns:\n",
    "        dict: json file content as a dictionary\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "\n",
    "topics = load_json('topics.json')['Topics']\n",
    "print(f\"The {len(topics)} topics are:\")\n",
    "print(\"\\n-\".join(topics.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a08dfe",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5a3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_name(section: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the section name from the document.\n",
    "\n",
    "    Args:\n",
    "        section (str): number of the section\n",
    "\n",
    "    Returns:\n",
    "        str: looked up section name\n",
    "    \"\"\"\n",
    "    sections = load_json('section_names.json')\n",
    "    return sections[section]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54227d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_string(pages: list) -> str:\n",
    "    \"\"\"\n",
    "    Get the string representation of the pages.\n",
    "\n",
    "    Args:\n",
    "        pages (list): list of pages\n",
    "\n",
    "    Returns:\n",
    "        str: string representation of the pages\n",
    "    \"\"\"\n",
    "    return \" and \".join([str(i) for i in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f2de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_metadata(metadata: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Preprocess the metadata to make it more readable.\n",
    "\n",
    "    Args:\n",
    "        metadata (dict): metadata of the document\n",
    "\n",
    "    Returns:\n",
    "        dict: preprocessed metadata\n",
    "    \"\"\"\n",
    "    #if 'section' in metadata:\n",
    "    metadata[\"section_name\"] = get_section_name(metadata[\"section\"])\n",
    "    metadata[\"page\"] = get_pages_string(metadata[\"page\"])\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d65b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for learning_chapter in topics:\n",
    "    #print(learning_chapter)\n",
    "    for section in topics[learning_chapter]:\n",
    "        #print(topics[learning_chapter][section])\n",
    "        for document in topics[learning_chapter][section]:\n",
    "            page_content = f\"{document[\"text\"]}\" #Maybe put the section name before the text for more context\n",
    "            #print(page_content)\n",
    "\n",
    "            metadata = preprocess_metadata(document[\"metadata\"])\n",
    "            #print(metadata)\n",
    "            documents.append(Document(page_content=page_content, metadata=metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c3316",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAIEmbeddings class\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Create a Chroma vector database OpenAI embeddings\n",
    "#db_openai = Chroma.from_documents(documents, embedding, persist_directory=\"./vectordb/openai_vectorDB\") #for new database\n",
    "db_openai = Chroma(persist_directory=\"./vectordb/openai_vectorDB\", embedding_function=embedding) #for existing database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd341519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_numbers(page_numbers: list[str]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Get the page numbers from the metadata.\n",
    "\n",
    "    Args:\n",
    "        page_numbers (list): list of page numbers\n",
    "\n",
    "    Returns:\n",
    "        list: sorted list of page numbers\n",
    "    \"\"\"\n",
    "    int_page_numbers = []\n",
    "    for page_number in page_numbers:\n",
    "        if \"and\" in page_number:\n",
    "            page_number = page_number.split(\" and \")\n",
    "            page_number = [int(i) for i in page_number]\n",
    "            int_page_numbers.extend(page_number)\n",
    "        else:\n",
    "            page_number = int(page_number)\n",
    "            int_page_numbers.append(page_number)\n",
    "    int_page_numbers.sort()\n",
    "\n",
    "    # Now we need to string them again\n",
    "    return [str(i) for i in int_page_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabc0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['140', '145', '205', '270']\n",
      "The conditions for a matrix to be invertible are as follows:\n",
      "\n",
      "1. The matrix is row-equivalent to the n x n identity matrix.\n",
      "2. The matrix has n pivot positions.\n",
      "3. The matrix is square and its determinant is not equal to 0.\n",
      "4. The matrix's columns form a linearly independent set.\n",
      "5. The mapping x â†¦ Ax is one-to-one.\n",
      "6. The equation Ax = b has at least one solution for each b in R^n.\n",
      "7. The columns of the matrix span R^n.\n",
      "8. The linear transformation x â†¦ Ax maps R^n onto R^n.\n",
      "9. There is an n x n matrix C such that CA = I (left inverse).\n",
      "10. There is an n x n matrix D such that AD = I (right inverse).\n",
      "11. The transpose of the matrix is also invertible.\n",
      "\n",
      "Additionally, the following statements are equivalent to a matrix being invertible:\n",
      "- The columns of the matrix form a basis of R^n.\n",
      "- The column space of the matrix is R^n.\n",
      "- The rank of the matrix is equal to n.\n",
      "- The nullity of the matrix is 0.\n",
      "- The null space of the matrix is {0}.\n",
      "References: pages 140, 145, 205, and 270\n"
     ]
    }
   ],
   "source": [
    "# Define a query\n",
    "query = \"Can you state all conditions for a matrix to be invertible?\"\n",
    "\n",
    "# Use the retriever to find relevant documents\n",
    "retrieved_docs = db_openai.similarity_search(query, k=4)\n",
    "\n",
    "# Prepare context from retrieved documents\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "references = get_page_numbers([doc.metadata['page'] for doc in retrieved_docs])\n",
    "#print(references)\n",
    "\n",
    "# Create a prompt for the LLM\n",
    "prompt = (\n",
    "    \"You are an assistant for question-answering tasks. Use the following pieces of \"\n",
    "    \"retrieved context to answer the question. If you don't know the answer, say that you \"\n",
    "    \"don't know.\"\n",
    "    \"\\n\\nContext:\\n\" + context + \"\\n\\nQuestion:\\n\" + query\n",
    ")\n",
    "\n",
    "# Use the LLM to generate an answer\n",
    "llm = OpenAI()\n",
    "\n",
    "resp = llm.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\",\"content\": query}\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_message = resp.choices[0].message.content\n",
    "print(response_message)\n",
    "print(f\"References: pages {\", \".join(references[:-1])}, and {references[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
