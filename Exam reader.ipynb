{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59efde30",
   "metadata": {},
   "source": [
    "# Intrinsic evaluation - Mock exams\n",
    "Dr. ir. M Bouss√© provided mock exams for the system to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bffc21",
   "metadata": {},
   "source": [
    "## Step 1 - Load data\n",
    "Load the .tex files and get the questions with their answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07692087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_question_answer(tex_content):\n",
    "    # Extract content within the enumerate environment\n",
    "    enum_match = re.search(r'\\\\begin{enumerate}(.*?)\\\\end{enumerate}', tex_content, re.DOTALL)\n",
    "    if not enum_match:\n",
    "        return [], []\n",
    "    enum_content = enum_match.group(1)\n",
    "\n",
    "    # Find all questions (\\item ... \\begin{solutionorbox})\n",
    "    question_blocks = re.findall(\n",
    "        r'\\\\item(.*?)(?=\\\\begin{solutionorbox})',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "    # Find all answers (\\begin{solutionorbox} ... \\end{solutionorbox})\n",
    "    answer_blocks = re.findall(\n",
    "        r'\\\\begin{solutionorbox}\\[[^\\]]*\\]\\s*(.*?)\\\\end{solutionorbox}',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "    questions = [q.strip() for q in question_blocks]\n",
    "    answers = [a.strip() for a in answer_blocks]\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2091bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Questions: 8\n",
      "Total Answers: 8\n",
      "\n",
      "Question 1:\n",
      "% new 2 \\ linear independence\n",
      "\tIf $\\{\\textbf{u},\\textbf{v}\\}$ is linearly independent and $\\{\\textbf{v},\\textbf{w}\\}$ is linearly independent, then so is $\\{\\textbf{u},\\textbf{v},\\textbf{w}\\}$.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 1:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tCounter-example: The set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 0 \\\\ 1\\end{bmatrix}\\right\\}$ is linearly dependent and the set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}\\right\\}$ is linearly dependent, but the set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 0 \\\\ 1\\end{bmatrix},\\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}\\right\\}$ is \\textbf{not} linearly dependent.\n",
      "\n",
      "Question 2:\n",
      "% variation of lecture\n",
      "\tLet $\\textbf{A}$ and $\\textbf{B}$ be two orthogonal matrices, then the product $\\textbf{A}\\textbf{B}$ is also \\textbf{always} orthogonal.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 2:\n",
      "\\textbf{True}.\n",
      "\t\tConsider two orthogonal matrices $\\textbf{A}$ and $\\textbf{B}$, i.e., we have that:\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t\\textbf{A}^\\text{T}\\textbf{A} &= \\textbf{I}, \\\\\n",
      "\t\t\t\t\\textbf{B}^\\text{T}\\textbf{B} &= \\textbf{I}. \n",
      "\t\t\t\\end{align*}\n",
      "\t\tThen the product is also orthogonal because\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t(\\textbf{A}\\textbf{B})^\\text{T}(\\textbf{A}\\textbf{B}) &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}\\textbf{A}\\textbf{B} \\\\\n",
      "\t\t\t\t&= \\textbf{B}^\\text{T}\\textbf{B}\\\\\n",
      "\t\t\t\t&= \\textbf{I}\n",
      "\t\t\t\\end{align*}\n",
      "\n",
      "Question 3:\n",
      "% new 2\n",
      "\tIf $\\lambda$ is an eigenvalue of $\\textbf{A}$, then it is also an eigenvalue of $\\textbf{A}^\\text{T}$.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 3:\n",
      "\\textbf{True}.\n",
      "\t\tWe can find eigenvalues via the characteristic equation:\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t\\text{det}(\\textbf{A}^\\text{T} - \\lambda \\textbf{I}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}(\\textbf{A}^\\text{T} - \\lambda \\textbf{I}^\\text{T}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}((\\textbf{A} - \\lambda \\textbf{I})^\\text{T}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}(\\textbf{A} - \\lambda \\textbf{I}) &= 0. \n",
      "\t\t\t\\end{align*}\n",
      "\t\tHence, the eigenvalues of $\\textbf{A}$ and $\\textbf{A}^\\text{T}$ are the same.\n",
      "\n",
      "Question 4:\n",
      "% variation of lecture [MOCK]\n",
      "\tThe product of two symmetric matrices is \\textbf{always} symmetric.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 4:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tConsider two symmetric matrices $\\textbf{A}$ and $\\textbf{B}$, i.e., we have that:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\textbf{A} &= \\textbf{A}^\\text{T}, \\\\\n",
      "\t\t\t\\textbf{B} &= \\textbf{B}^\\text{T}, \\\\\n",
      "\t\t\\end{align*}\n",
      "\t\tThe product is not symmetric because:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\left(\\textbf{A}\\textbf{B}\\right)^\\text{T} &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}, \\\\\n",
      "\t\t\t&= \\textbf{B}\\textbf{A},\n",
      "\t\t\\end{align*}\n",
      "\t\tand matrix multiplication is not commutative.\n",
      "\n",
      "Question 5:\n",
      "% [STUDENT1] \n",
      "\tIn order to construct an eigenvector basis of $\\mathbb{R}^n$ from a matrix $\\textbf{A}$, $\\textbf{A}$ must have $n$ \\textbf{distinct} eigenvalues.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "%\t(\\emph{Thanks to Riva for the inspiration!})\n",
      "\n",
      "Answer 5:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tIn order to construct an eigenvector basis of $\\mathbb{R}^n$ from a matrix $\\textbf{A}$, we need $n$ linearly independent eigenvectors (by the diagonalization theorem), which can be found from less than $n$ (distinct) eigenvalues.\n",
      "\t\t\n",
      "\t\tCounter-example: $\\textbf{A} = \\textbf{I}$.\n",
      "\n",
      "Question 6:\n",
      "% variation of weekly quiz [EXAM21]\n",
      "\tThe columns of \\textbf{any} $2 \\times 2$ \\textbf{rotation} matrix form an orthogonal set.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 6:\n",
      "\\textbf{True}.\n",
      "\t\t\n",
      "\t\tThe rotation matrix is given by $\\begin{bmatrix} \\cos \\phi & -\\sin \\phi \\\\ \\sin \\phi & \\cos \\phi \\end{bmatrix}$. The inner product of the columns is given by\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\begin{bmatrix}\n",
      "\t\t\t\t\\cos \\phi & \\sin \\phi \n",
      "\t\t\t\\end{bmatrix}\n",
      "\t\t\t\\begin{bmatrix}\n",
      "\t\t\t\t-\\sin \\phi \\\\\n",
      "\t\t\t\t\\cos \\phi\n",
      "\t\t\t\\end{bmatrix}\n",
      "\t\t\t= -\\cos \\phi \\sin \\phi + \\cos \\phi \\sin \\phi = 0.\n",
      "\t\t\\end{align*}\n",
      "\n",
      "Question 7:\n",
      "% [NEW1]\n",
      "\tSuppose $\\textbf{A}$ is an $n \\times n$ symmetric matrix and $\\textbf{B}$ is \\textbf{any} $n \\times m$ matrix, then $\\textbf{B}^\\text{T}\\textbf{A}\\textbf{B}$ and $\\textbf{B}^\\text{T}\\textbf{B}$ are symmetric matrices.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 7:\n",
      "\\textbf{True}.\n",
      "\t\tFirst, note that:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t(\\textbf{B}^\\text{T}\\textbf{A}\\textbf{B})^\\text{T} &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}\\textbf{B}^\\text{T$^\\text{T}$} = \\textbf{B}^\\text{T}\\textbf{A}\\textbf{B}.\n",
      "\t\t\\end{align*}\t\n",
      "\t\tThe second one holds because the first one also holds for $\\textbf{A} = \\textbf{I}$.\n",
      "\n",
      "Question 8:\n",
      "% new 2\n",
      "\t\\textbf{Every} orthogonal set in $\\mathbb{R}^n$ is linearly independent.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 8:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tCounter-example: The set $\\left\\{ \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right\\}$ is clearly orthogonal because the zero vector is orthogonal to every vector, but the set is clearly not linearly independent because every set that contains the zero vector is linearly dependent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split out True/False questions\n",
    "exam_questions_TF = []\n",
    "exam_answers_TF = []\n",
    "\n",
    "\n",
    "with open('exams/together.tex', 'r', encoding='utf-8') as file:\n",
    "    tex_content = file.read()\n",
    "    questions, answers = extract_question_answer(tex_content)\n",
    "    print(f\"Total Questions: {len(questions)}\")\n",
    "    print(f\"Total Answers: {len(answers)}\")\n",
    "    if len(questions) != len(answers):\n",
    "        print(\"Warning: The number of questions and answers do not match!\")\n",
    "\n",
    "    \n",
    "    print()\n",
    "    for idx, (q, a) in enumerate(zip(questions, answers), 1):\n",
    "        print(f\"Question {idx}:\\n{q}\\n\")\n",
    "        print(f\"Answer {idx}:\\n{a}\\n\")\n",
    "        exam_questions_TF.append(q)\n",
    "        exam_answers_TF.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc192c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: exams/together.tex\n",
      "Total Questions: 8\n",
      "Total Answers: 8\n",
      "\n",
      "Question 1:\n",
      "% new 2 \\ linear independence\n",
      "\tIf $\\{\\textbf{u},\\textbf{v}\\}$ is linearly independent and $\\{\\textbf{v},\\textbf{w}\\}$ is linearly independent, then so is $\\{\\textbf{u},\\textbf{v},\\textbf{w}\\}$.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 1:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tCounter-example: The set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 0 \\\\ 1\\end{bmatrix}\\right\\}$ is linearly dependent and the set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}\\right\\}$ is linearly dependent, but the set $\\left\\{\\begin{bmatrix} 1 \\\\ 0\\end{bmatrix},\\begin{bmatrix} 0 \\\\ 1\\end{bmatrix},\\begin{bmatrix} 1 \\\\ 1\\end{bmatrix}\\right\\}$ is \\textbf{not} linearly dependent.\n",
      "\n",
      "----------------------------------------\n",
      "Question 2:\n",
      "% variation of lecture\n",
      "\tLet $\\textbf{A}$ and $\\textbf{B}$ be two orthogonal matrices, then the product $\\textbf{A}\\textbf{B}$ is also \\textbf{always} orthogonal.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 2:\n",
      "\\textbf{True}.\n",
      "\t\tConsider two orthogonal matrices $\\textbf{A}$ and $\\textbf{B}$, i.e., we have that:\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t\\textbf{A}^\\text{T}\\textbf{A} &= \\textbf{I}, \\\\\n",
      "\t\t\t\t\\textbf{B}^\\text{T}\\textbf{B} &= \\textbf{I}. \n",
      "\t\t\t\\end{align*}\n",
      "\t\tThen the product is also orthogonal because\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t(\\textbf{A}\\textbf{B})^\\text{T}(\\textbf{A}\\textbf{B}) &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}\\textbf{A}\\textbf{B} \\\\\n",
      "\t\t\t\t&= \\textbf{B}^\\text{T}\\textbf{B}\\\\\n",
      "\t\t\t\t&= \\textbf{I}\n",
      "\t\t\t\\end{align*}\n",
      "\n",
      "----------------------------------------\n",
      "Question 3:\n",
      "% new 2\n",
      "\tIf $\\lambda$ is an eigenvalue of $\\textbf{A}$, then it is also an eigenvalue of $\\textbf{A}^\\text{T}$.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 3:\n",
      "\\textbf{True}.\n",
      "\t\tWe can find eigenvalues via the characteristic equation:\n",
      "\t\t\t\\begin{align*}\n",
      "\t\t\t\t\\text{det}(\\textbf{A}^\\text{T} - \\lambda \\textbf{I}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}(\\textbf{A}^\\text{T} - \\lambda \\textbf{I}^\\text{T}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}((\\textbf{A} - \\lambda \\textbf{I})^\\text{T}) &= 0, \\\\\n",
      "\t\t\t\t\\text{det}(\\textbf{A} - \\lambda \\textbf{I}) &= 0. \n",
      "\t\t\t\\end{align*}\n",
      "\t\tHence, the eigenvalues of $\\textbf{A}$ and $\\textbf{A}^\\text{T}$ are the same.\n",
      "\n",
      "----------------------------------------\n",
      "Question 4:\n",
      "% variation of lecture [MOCK]\n",
      "\tThe product of two symmetric matrices is \\textbf{always} symmetric.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 4:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tConsider two symmetric matrices $\\textbf{A}$ and $\\textbf{B}$, i.e., we have that:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\textbf{A} &= \\textbf{A}^\\text{T}, \\\\\n",
      "\t\t\t\\textbf{B} &= \\textbf{B}^\\text{T}, \\\\\n",
      "\t\t\\end{align*}\n",
      "\t\tThe product is not symmetric because:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\left(\\textbf{A}\\textbf{B}\\right)^\\text{T} &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}, \\\\\n",
      "\t\t\t&= \\textbf{B}\\textbf{A},\n",
      "\t\t\\end{align*}\n",
      "\t\tand matrix multiplication is not commutative.\n",
      "\n",
      "----------------------------------------\n",
      "Question 5:\n",
      "% [STUDENT1] \n",
      "\tIn order to construct an eigenvector basis of $\\mathbb{R}^n$ from a matrix $\\textbf{A}$, $\\textbf{A}$ must have $n$ \\textbf{distinct} eigenvalues.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "%\t(\\emph{Thanks to Riva for the inspiration!})\n",
      "\n",
      "Answer 5:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tIn order to construct an eigenvector basis of $\\mathbb{R}^n$ from a matrix $\\textbf{A}$, we need $n$ linearly independent eigenvectors (by the diagonalization theorem), which can be found from less than $n$ (distinct) eigenvalues.\n",
      "\t\t\n",
      "\t\tCounter-example: $\\textbf{A} = \\textbf{I}$.\n",
      "\n",
      "----------------------------------------\n",
      "Question 6:\n",
      "% variation of weekly quiz [EXAM21]\n",
      "\tThe columns of \\textbf{any} $2 \\times 2$ \\textbf{rotation} matrix form an orthogonal set.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 6:\n",
      "\\textbf{True}.\n",
      "\t\t\n",
      "\t\tThe rotation matrix is given by $\\begin{bmatrix} \\cos \\phi & -\\sin \\phi \\\\ \\sin \\phi & \\cos \\phi \\end{bmatrix}$. The inner product of the columns is given by\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t\\begin{bmatrix}\n",
      "\t\t\t\t\\cos \\phi & \\sin \\phi \n",
      "\t\t\t\\end{bmatrix}\n",
      "\t\t\t\\begin{bmatrix}\n",
      "\t\t\t\t-\\sin \\phi \\\\\n",
      "\t\t\t\t\\cos \\phi\n",
      "\t\t\t\\end{bmatrix}\n",
      "\t\t\t= -\\cos \\phi \\sin \\phi + \\cos \\phi \\sin \\phi = 0.\n",
      "\t\t\\end{align*}\n",
      "\n",
      "----------------------------------------\n",
      "Question 7:\n",
      "% [NEW1]\n",
      "\tSuppose $\\textbf{A}$ is an $n \\times n$ symmetric matrix and $\\textbf{B}$ is \\textbf{any} $n \\times m$ matrix, then $\\textbf{B}^\\text{T}\\textbf{A}\\textbf{B}$ and $\\textbf{B}^\\text{T}\\textbf{B}$ are symmetric matrices.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 7:\n",
      "\\textbf{True}.\n",
      "\t\tFirst, note that:\n",
      "\t\t\\begin{align*}\n",
      "\t\t\t(\\textbf{B}^\\text{T}\\textbf{A}\\textbf{B})^\\text{T} &= \\textbf{B}^\\text{T}\\textbf{A}^\\text{T}\\textbf{B}^\\text{T$^\\text{T}$} = \\textbf{B}^\\text{T}\\textbf{A}\\textbf{B}.\n",
      "\t\t\\end{align*}\t\n",
      "\t\tThe second one holds because the first one also holds for $\\textbf{A} = \\textbf{I}$.\n",
      "\n",
      "----------------------------------------\n",
      "Question 8:\n",
      "% new 2\n",
      "\t\\textbf{Every} orthogonal set in $\\mathbb{R}^n$ is linearly independent.\n",
      "\t\n",
      "\t\\begin{itemize}\n",
      "\t\t\\item[$\\square$] True\n",
      "\t\t\\item[$\\square$] False\n",
      "\t\\end{itemize}\n",
      "\n",
      "Answer 8:\n",
      "\\textbf{False}.\n",
      "\t\t\n",
      "\t\tCounter-example: The set $\\left\\{ \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right\\}$ is clearly orthogonal because the zero vector is orthogonal to every vector, but the set is clearly not linearly independent because every set that contains the zero vector is linearly dependent.\n",
      "\n",
      "----------------------------------------\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "exam_questions = []\n",
    "exam_answers = []\n",
    "\n",
    "# Split out True/False questions\n",
    "exam_questions_TF = []\n",
    "exam_answers_TF = []\n",
    "\n",
    "# Split out construction questions\n",
    "exam_questions_construction = []\n",
    "exam_answers_construction = []\n",
    "\n",
    "exam_files = [\n",
    "    'exams/together.tex',\n",
    "]\n",
    "for exam_file in exam_files:\n",
    "    with open(exam_file, 'r', encoding='utf-8') as file:\n",
    "        tex_content = file.read()\n",
    "        questions, answers = extract_question_answer(tex_content)\n",
    "        print(f\"Processing file: {exam_file}\")\n",
    "        print(f\"Total Questions: {len(questions)}\")\n",
    "        print(f\"Total Answers: {len(answers)}\")\n",
    "        if len(questions) != len(answers):\n",
    "            print(\"Warning: The number of questions and answers do not match!\")\n",
    "        exam_questions.extend(questions)\n",
    "        exam_answers.extend(answers)\n",
    "\n",
    "        \n",
    "        print()\n",
    "        for idx, (q, a) in enumerate(zip(questions, answers), 1):\n",
    "            print(f\"Question {idx}:\\n{q}\\n\")\n",
    "            print(f\"Answer {idx}:\\n{a}\\n\")\n",
    "            print(\"-\" * 40)\n",
    "            if \"construction\" in q:\n",
    "                exam_questions_construction.append(q)\n",
    "                exam_answers_construction.append(a)\n",
    "            else:\n",
    "                exam_questions_TF.append(q)\n",
    "                exam_answers_TF.append(a)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b898b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Questions across all exams: 8\n",
      "Total Answers across all exams: 8\n"
     ]
    }
   ],
   "source": [
    "# Print total counts\n",
    "print(f\"Total Questions across all exams: {len(exam_questions)}\")\n",
    "print(f\"Total Answers across all exams: {len(exam_answers)}\")\n",
    "\n",
    "assert len(exam_questions) == len(exam_answers), \"Mismatch between total questions and answers across all exams.\"\n",
    "#assert len(exam_questions) == 108, \"Manually calculated number of questions/answers does not match.\"\n",
    "\n",
    "#assert len(exam_answers_construction) == 6*len(exam_files), \"Manually calculated number of construction exercises does not match.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b225be8",
   "metadata": {},
   "source": [
    "## Step 2 - Setup system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d82b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "OPENAI_API = os.getenv('OPENAI_API_KEY')\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=OPENAI_API)\n",
    "db_openai = Chroma(persist_directory=\"./vectordb/openai_vectorDB/\", embedding_function=embedding) #for existing database\n",
    "llm = OpenAI(api_key=OPENAI_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447bf29",
   "metadata": {},
   "source": [
    "## Step 3 - Evaluate with system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1439c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_llm_answer_openai(exam_question, prompt, openai_model, use_RAG=False, k=4) -> str:\n",
    "    if use_RAG == True:\n",
    "        if k == 0:\n",
    "            return \"Error retrieving\"\n",
    "        # Retrieve relevant context from the vector database\n",
    "        retrieved_docs = db_openai.similarity_search(exam_question, k=k)\n",
    "        context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "        rag_prompt = (\n",
    "            \"Use the following pieces of retrieved context to answer the question. \"\n",
    "            \"\\n\\nContext:\\n\" + context\n",
    "        )\n",
    "        prompt = prompt + rag_prompt\n",
    "\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": exam_question})\n",
    "\n",
    "    try:\n",
    "        response = llm.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {exam_question}\\nError: {e}\")\n",
    "        answer = get_llm_answer_openai(exam_question, prompt, openai_model, use_RAG, k=k-1)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def get_llm_answers_openai(exam_questions_TF, prompt, openai_model, use_RAG=False) -> list[str]:\n",
    "    llm_answers_TF = []\n",
    "    for question in tqdm(exam_questions_TF):\n",
    "        llm_answers_TF.append(get_llm_answer_openai(question, prompt, openai_model, use_RAG=use_RAG))\n",
    "    return llm_answers_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a182145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    def get_llm_answer_openai(exam_questions_TF, prompt, openai_model, use_RAG=False, k=4) -> list[str]:\n",
    "        if k == 0:\n",
    "            return \n",
    "        llm_answers_TF = []\n",
    "\n",
    "        for question in tqdm(exam_questions_TF):\n",
    "            if use_RAG == True:\n",
    "                # Retrieve relevant context from the vector database\n",
    "                retrieved_docs = db_openai.similarity_search(question, k=k)\n",
    "                context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "                rag_prompt = (\n",
    "                    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                    \"\\n\\nContext:\\n\" + context\n",
    "                )\n",
    "                prompt = prompt + rag_prompt\n",
    "\n",
    "            messages = []\n",
    "            messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "            messages.append({\"role\": \"user\", \"content\": question})\n",
    "            \n",
    "            try:\n",
    "                response = llm.chat.completions.create(\n",
    "                    model=openai_model,\n",
    "                    messages=messages,\n",
    "                )\n",
    "                answer = response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing question: {question}\\nError: {e}\")\n",
    "                try:\n",
    "                    if use_RAG == True:\n",
    "                        # Retrieve relevant context from the vector database\n",
    "                        retrieved_docs = db_openai.similarity_search(question, k=3)\n",
    "                        context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "                        rag_prompt = (\n",
    "                            \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                            \"\\n\\nContext:\\n\" + context\n",
    "                        )\n",
    "                        prompt = prompt + rag_prompt\n",
    "\n",
    "                    messages = []\n",
    "                    messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "                    messages.append({\"role\": \"user\", \"content\": question})\n",
    "                    response = llm.chat.completions.create(\n",
    "                        model=openai_model,\n",
    "                        messages=messages,\n",
    "                    )\n",
    "                    answer = response.choices[0].message.content\n",
    "                except Exception as e:\n",
    "                    print(f\"Retry failed for question: {question}\\nError: {e}\")\n",
    "                    answer = \"Error retrieving answer\"\n",
    "            llm_answers_TF.append(answer)\n",
    "        return llm_answers_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e46e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_llm(llm_answers: list[str]) -> list[str]:\n",
    "    cleaned_answers = []\n",
    "    for org_answer in llm_answers:\n",
    "        answer = org_answer.lower()\n",
    "        if \"true\" in answer and \"false\" in answer:\n",
    "            #print(\"Case 1\")\n",
    "            # Check if one is bold that overrules the other\n",
    "            # For example, an answer is bold, and there is \"not true\" in the answer too\n",
    "            if \"\\\\textbf{false}\" in answer and \"\\\\textbf{true}\" in answer:\n",
    "                print(\"Warning: Both True and False found in the answer, CONFLICT.\")\n",
    "                print(\"Answer:\", answer)\n",
    "                print(\"Index:\", llm_answers.index(org_answer))\n",
    "                print(40* \"-\")\n",
    "                cleaned_answers.append(\"CONFLICT\")\n",
    "            # Give priority to bold answer or final conclusion in the beginning of the answer\n",
    "            elif \"\\\\textbf{false}\" in answer or \"false\" in answer[:5]: \n",
    "                cleaned_answers.append(\"False\")\n",
    "            elif \"\\\\textbf{true}\" in answer or \"true\" in answer[:5]:\n",
    "                cleaned_answers.append(\"True\")\n",
    "            else:\n",
    "                print(\"Warning: unchecked case.\")\n",
    "                print(\"Answer:\", answer)\n",
    "                print(\"Index:\", llm_answers.index(org_answer))\n",
    "                print(40* \"-\")\n",
    "                cleaned_answers.append(\"CONFLICT\")\n",
    "        else:\n",
    "            #print(\"Case 2\")\n",
    "            if \"true\" in answer or \"\\\\textbf{true}\" in answer:\n",
    "                cleaned_answers.append(\"True\")\n",
    "            elif \"false\" in answer or \"\\\\textbf{False}\" in answer:\n",
    "                cleaned_answers.append(\"False\")\n",
    "            else:\n",
    "                print(\"Warning: Neither True nor False found in the answer, CONFLICT.\")\n",
    "                print(\"Answer:\", answer)\n",
    "                print(\"Index:\", llm_answers.index(org_answer))\n",
    "                print(40* \"-\")\n",
    "                cleaned_answers.append(\"CONFLICT\")\n",
    "    return cleaned_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c895615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answers_Martijn(true_answers: list[str]) -> list[str]:\n",
    "    cleaned_answers = []\n",
    "    for org_answer in true_answers:\n",
    "        answer = org_answer.lower()\n",
    "        if \"\\\\textbf{false}\" in answer:\n",
    "            cleaned_answers.append(\"False\")\n",
    "        elif \"\\\\textbf{true}\" in answer:\n",
    "            cleaned_answers.append(\"True\")\n",
    "        else:\n",
    "            print(\"Warning: Neither True nor False found in the Martijn's answer, CONFLICT.\")\n",
    "            print(\"Answer:\", answer)\n",
    "            print(\"Index:\", true_answers.index(org_answer))\n",
    "            print(\"CONFLICT MARTIJN\")\n",
    "        #cleaned_answers.append(\"True\")\n",
    "    return cleaned_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef43599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(Martijn_answers: list[str], llm_answers: list[str]) -> float:\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for Martijn_answer, llm_answer in zip(Martijn_answers, llm_answers):\n",
    "        if Martijn_answer.lower() == llm_answer.lower():\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    total = correct + incorrect\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb89d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_dataframe(questions: list[str], llm_answers: list[str], Martijn_answers: list[str]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\n",
    "        'Question': questions,\n",
    "        'LLM Answer': llm_answers,\n",
    "        'Martijn Answer': Martijn_answers\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f18d6",
   "metadata": {},
   "source": [
    "### Step 3.1 - Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"gpt-3.5-turbo\" #gpt-3.5-turbo-0125\n",
    "custom_prompt = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a True/False statement. You must include 'True', 'False' or 'I don't know' in your answer. \"\n",
    "    \"If the statement is 'False', a counter-example is sufficient. \"\n",
    "    \"If the statement is 'True', you briefly outline a proof and/or mention relevant theorems. \"\n",
    "    \"If you are not sure, you say 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    ")\n",
    "custom_prompt_construction = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a question to construct. \"\n",
    "    \"If you do not know the answer, respond with 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955241b",
   "metadata": {},
   "source": [
    "True/False questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19dd797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [03:04<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_TF = get_llm_answers_openai(exam_questions_TF, custom_prompt, openai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9af3311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LLM answers compared to Martijn's answers: 46.43%\n"
     ]
    }
   ],
   "source": [
    "llm_answers_cleaned = extract_answer_llm(llm_answers_TF)\n",
    "Martijn_answers = extract_answers_Martijn(exam_answers_TF)\n",
    "\n",
    "assert len(llm_answers_cleaned) == len(Martijn_answers), \"Mismatch between LLM answers and Martijn's answers.\"\n",
    "\n",
    "accuracy = compute_accuracy(Martijn_answers, llm_answers_cleaned)\n",
    "print(f\"Accuracy of LLM answers compared to Martijn's answers: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c00969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_TF = convert_dataframe(\n",
    "    exam_questions_TF,\n",
    "    llm_answers_TF,\n",
    "    exam_answers_TF\n",
    ")\n",
    "df_baseline_GPT3_5_TF.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_TF_3.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_TF.pkl\")\n",
    "#df_baseline_GPT3_5_TF.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_TF.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776c18d",
   "metadata": {},
   "source": [
    "Construction questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f7e9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:42<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_construction = get_llm_answers_openai(exam_answers_construction, custom_prompt_construction, openai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b051becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_construction = convert_dataframe(\n",
    "    exam_questions_construction,\n",
    "    llm_answers_construction,\n",
    "    exam_answers_construction\n",
    ")\n",
    "df_baseline_GPT3_5_construction.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_Construction.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_Construction.pkl\")\n",
    "#df_baseline_GPT3_5_construction.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_Construction.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97035ca0",
   "metadata": {},
   "source": [
    "### Step 3.2 - Baseline LLM + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"gpt-3.5-turbo\" #gpt-3.5-turbo-0125\n",
    "custom_prompt = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a True/False statement. You must include 'True', 'False' or 'I don't know' in your answer. \"\n",
    "    \"If the statement is 'False', a counter-example is sufficient. \"\n",
    "    \"If the statement is 'True', you briefly outline a proof and/or mention relevant theorems. \"\n",
    "    \"If you are not sure, you say 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    ")\n",
    "custom_prompt_construction = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a question to construct. \"\n",
    "    \"If you do not know the answer, respond with 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485df8a",
   "metadata": {},
   "source": [
    "True/False questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c7ff758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [03:33<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_TF = get_llm_answers_openai(exam_questions_TF, custom_prompt, openai_model, use_RAG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85cf1906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains \"Error retrieving\": False\n"
     ]
    }
   ],
   "source": [
    "error_present = any(\"Error retrieving\" in answer for answer in llm_answers_TF)\n",
    "print(f'Contains \"Error retrieving\": {error_present}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83026601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LLM answers compared to Martijn's answers: 44.05%\n"
     ]
    }
   ],
   "source": [
    "llm_answers_cleaned = extract_answer_llm(llm_answers_TF)\n",
    "Martijn_answers = extract_answers_Martijn(exam_answers_TF)\n",
    "\n",
    "accuracy = compute_accuracy(Martijn_answers, llm_answers_cleaned)\n",
    "print(f\"Accuracy of LLM answers compared to Martijn's answers: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_RAG_TF = convert_dataframe(\n",
    "    exam_questions_TF,\n",
    "    llm_answers_TF,\n",
    "    exam_answers_TF\n",
    ")\n",
    "df_baseline_GPT3_5_RAG_TF.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_TF_3.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_TF.pkl\")\n",
    "#df_baseline_GPT3_5_RAG_TF.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_TF.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa71b1",
   "metadata": {},
   "source": [
    "Construction questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1264fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:57<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_construction = get_llm_answers_openai(exam_answers_construction, custom_prompt_construction, openai_model, use_RAG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_RAG_construction = convert_dataframe(\n",
    "    exam_questions_construction,\n",
    "    llm_answers_construction,\n",
    "    exam_answers_construction\n",
    ")\n",
    "df_baseline_GPT3_5_RAG_construction.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_Construction.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_Construction.pkl\")\n",
    "#df_baseline_GPT3_5_RAG_construction.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_RAG_Construction.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8ee0a",
   "metadata": {},
   "source": [
    "### Step 4.1 - Baseline LLM + all-in-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2dcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load the JSON file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): name of the file to load\n",
    "\n",
    "    Returns:\n",
    "        dict: json file content as a dictionary\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    return file\n",
    "\n",
    "topics = load_json('topics.json')['Topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f35faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 65 theorems.\n"
     ]
    }
   ],
   "source": [
    "theorems = []\n",
    "for topic in topics.values():\n",
    "    for section, items in topic.items():\n",
    "        for item in items:\n",
    "            if isinstance(item, dict) and \"metadata\" in item:\n",
    "                if item[\"metadata\"].get(\"type\") == \"theorem\":\n",
    "                    theorems.append(item)\n",
    "print(f\"There are {len(theorems)} theorems.\")\n",
    "theorems_text = [theorem['text'] for theorem in theorems] #only get the text of the theorems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf94275",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"gpt-3.5-turbo\" #gpt-3.5-turbo-0125\n",
    "custom_prompt = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a True/False statement. You must include 'True', 'False' or 'I don't know' in your answer. \"\n",
    "    \"If the statement is 'False', a counter-example is sufficient. \"\n",
    "    \"If the statement is 'True', you briefly outline a proof and/or mention relevant theorems. \"\n",
    "    \"If you are not sure, you say 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    "    \"You can use the following theorems to answer the question. \" + \"\\n\\n\".join(theorems_text)\n",
    ")\n",
    "custom_prompt_construction = (\n",
    "    \"You are an assistant for question-answering tasks in linear algebra. \"\n",
    "    \"Your are given a question to construct. \"\n",
    "    \"If you do not know the answer, respond with 'I don't know'. \"\n",
    "    \"Please use LaTeX formatting for mathematical expressions by writing them between dollar signs.\"\n",
    "    \"For example, to write a matrix, use $\\\\begin{pmatrix} a & b \\\\\\\\ c & d \\\\end{pmatrix}$. \"\n",
    "    \"You can use the following theorems to answer the question. \" + \"\\n\\n\".join(theorems_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b5cb",
   "metadata": {},
   "source": [
    "True/False questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9235f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [02:55<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_TF = get_llm_answers_openai(exam_questions_TF, custom_prompt, openai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5521d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LLM answers compared to Martijn's answers: 63.10%\n"
     ]
    }
   ],
   "source": [
    "llm_answers_cleaned = extract_answer_llm(llm_answers_TF)\n",
    "Martijn_answers = extract_answers_Martijn(exam_answers_TF)\n",
    "\n",
    "accuracy = compute_accuracy(Martijn_answers, llm_answers_cleaned)\n",
    "print(f\"Accuracy of LLM answers compared to Martijn's answers: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_PROMPT_TF = convert_dataframe(\n",
    "    exam_questions_TF,\n",
    "    llm_answers_TF,\n",
    "    exam_answers_TF\n",
    ")\n",
    "df_baseline_GPT3_5_PROMPT_TF.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_TF_3.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_TF.pkl\")\n",
    "#df_baseline_GPT3_5_PROMPT_TF.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_TF.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4690f",
   "metadata": {},
   "source": [
    "Construction questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc89c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:48<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_answers_construction = get_llm_answers_openai(exam_answers_construction, custom_prompt_construction, openai_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d76115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_GPT3_5_PROMPT_construction = convert_dataframe(\n",
    "    exam_questions_construction,\n",
    "    llm_answers_construction,\n",
    "    exam_answers_construction\n",
    ")\n",
    "df_baseline_GPT3_5_PROMPT_construction.to_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_Construction.pkl\")\n",
    "#temp = pd.read_pickle(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_Construction.pkl\")\n",
    "#df_baseline_GPT3_5_PROMPT_construction.to_csv(\"results/GPT-3_5-Turbo/baseline_GPT3_5_PROMPT_Construction.csv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
