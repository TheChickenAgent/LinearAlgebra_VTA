{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f3f42e",
   "metadata": {},
   "source": [
    "# Gemini notebook\n",
    "\n",
    "| Pedagogy Dimension | Metrics |\n",
    "| --- | ----------- |\n",
    "| Manage cognitive load | Stay on topic |\n",
    "| Encourage active learning | Do not reveal the answer; guide towards the answer; promote active engagement |\n",
    "| Deepen metacognition | Identify and address misconceptions |\n",
    "| Motivate and stimulate curiosity | Communicate with positive tone; respond appropriately to explicit affect cues |\n",
    "| Adapt to the learners’ goals and needs | Adapt to the learner’s level |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15f9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "DATA_DIR = \"user-testing/data/\"\n",
    "\n",
    "def list_pickle_files(directory):\n",
    "    return [f for f in os.listdir(directory) if f.endswith('.pkl')]\n",
    "\n",
    "def load_conversation(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "def read_questions_answers():\n",
    "    # Split out True/False questions\n",
    "    exam_questions_TF = []\n",
    "    exam_answers_TF = []\n",
    "\n",
    "    with open('exams/together2.tex', 'r', encoding='utf-8') as file:\n",
    "        tex_content = file.read()\n",
    "        questions, answers = extract_question_answer(tex_content)\n",
    "        #print(f\"Total Questions: {len(questions)}\")\n",
    "        #print(f\"Total Answers: {len(answers)}\")\n",
    "        if len(questions) != len(answers):\n",
    "            print(\"Warning: The number of questions and answers do not match!\")\n",
    " \n",
    "        #print()\n",
    "        for idx, (q, a) in enumerate(zip(questions, answers), 1):\n",
    "            #print(f\"Question {idx}:\\n{q}\\n\")\n",
    "            #print(f\"Answer {idx}:\\n{a}\\n\")\n",
    "            exam_questions_TF.append(q)\n",
    "            exam_answers_TF.append(a)\n",
    "    return exam_questions_TF, exam_answers_TF\n",
    "\n",
    "def extract_question_answer(tex_content):\n",
    "    # Extract content within the enumerate environment\n",
    "    enum_match = re.search(r'\\\\begin{enumerate}(.*?)\\\\end{enumerate}', tex_content, re.DOTALL)\n",
    "    if not enum_match:\n",
    "        return [], []\n",
    "    enum_content = enum_match.group(1)\n",
    "\n",
    "    # Find all questions (\\item ... \\begin{solutionorbox})\n",
    "    question_blocks = re.findall(\n",
    "        r'\\\\item(.*?)(?=\\\\begin{solutionorbox})',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "\n",
    "    # Find all answers (\\begin{solutionorbox} ... \\end{solutionorbox})\n",
    "    answer_blocks = re.findall(\n",
    "        r'\\\\begin{solutionorbox}\\[[^\\]]*\\]\\s*(.*?)\\\\end{solutionorbox}',\n",
    "        enum_content, re.DOTALL\n",
    "    )\n",
    "    questions = [q.strip() for q in question_blocks]\n",
    "    answers = [a.strip() for a in answer_blocks]\n",
    "    return questions, answers\n",
    "\n",
    "def remove_latex_formatting(question: str) -> str:\n",
    "    # Remove LaTeX bold formatting\n",
    "    question = question.replace(\"\\\\textbf{always}\", \"*always*\")  \n",
    "    question = question.replace(\"\\\\textbf{Every}\", \"*Every*\")\n",
    "    question = question.replace(\"\\\\textbf{any}\", \"*any*\")\n",
    "    question = question.replace(\"\\\\textbf{rotation}\", \"*rotation*\")\n",
    "    question = question.replace(\"\\\\textbf{distinct}\", \"*distinct*\")\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "GOOGLE_API = os.getenv('GOOGLE_API_KEY')\n",
    "client = genai.Client(api_key=GOOGLE_API)\n",
    "gemini_model = \"gemini-2.5-flash\"\n",
    "\n",
    "o4_llm_state = pickle.load(open('exams/together2_llm_state.pkl', 'rb'))\n",
    "exam_questions_TF, exam_answers_TF = read_questions_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_on_topic = \"\"\"\n",
    "You are a Critic assessing a Tutor who is interacting with a Student.\n",
    "The Tutor should attempt to keep the conversation focused on the topic\n",
    "of the lesson, even when the Student says something off-topic.\n",
    "As the Critic, you identify when the Tutor believes the Student is off-\n",
    "topic. You are *not* responsible for determining whether the Student\n",
    "is actually off-topic; only for determining whether the Tutor *\n",
    "believes* the Student is off-topic.\n",
    "You are also not responsible for judging whether the Tutor’s response\n",
    "is correct, helpful, or safe; only for determining whether it\n",
    "believes the Student is off-topic.\n",
    "Your answer should always be \"Yes\" or \"No\".\n",
    "Answer with \"Yes\" if the Tutor’s response indicates a belief that the\n",
    "Student is off-topic.\n",
    "Answer with \"No\" if the Tutor does not believe the Student is off-topic.\n",
    "\n",
    "***new lesson***\n",
    "Student: What is the shape of the Earth?\n",
    "Tutor: That’s an interesting question, but not related to the lesson.\n",
    "Request: Does the Tutor believe the Student is off-topic?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: How many phosphates are in ATP?\n",
    "Tutor: Three! ATP stands for Adenosine triphosphate (where the \"tri-\"\n",
    "stands for 3 phosphates).\n",
    "Request: Does the Tutor believe the Student is off-topic?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Give me a quiz!\n",
    "Tutor: Sure thing. Here’s the first question: where was Nikola Tesla\n",
    "born?\n",
    "Request: Does the Tutor believe the Student is off-topic?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: How many phosphates are in ATP?\n",
    "Tutor: Could you clarify how this question relates to lesson?\n",
    "Request: Does the Tutor believe the Student is off-topic?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe0b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_role_prefix_to_conversation(conversation):\n",
    "    \"\"\"\n",
    "    Returns a new conversation list where each message's content is prefixed\n",
    "    with 'Student:' or 'Tutor:' depending on the role.\n",
    "\n",
    "    Args:\n",
    "        conversation (list): List of dicts with 'role' and 'content'.\n",
    "\n",
    "    Returns:\n",
    "        list: New conversation list with prefixed content.\n",
    "    \"\"\"\n",
    "    role_prefix = {'user': 'Student:', 'assistant': 'Tutor:'}\n",
    "    new_conversation = []\n",
    "    for msg in conversation:\n",
    "        prefix = role_prefix.get(msg['role'], '')\n",
    "        new_content = f\"{prefix} {msg['content'].strip()}\"\n",
    "        new_conversation.append({'role': msg['role'], 'content': new_content})\n",
    "    return new_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ed910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_message_contents(messages):\n",
    "    \"\"\"\n",
    "    Joins the 'content' field of each message in the list with two new lines.\n",
    "\n",
    "    Args:\n",
    "        messages (list): List of dicts with a 'content' key.\n",
    "\n",
    "    Returns:\n",
    "        str: Joined string of all message contents separated by two new lines.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(msg['content'] for msg in messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555982c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def get_critic_scores(critic_prompt, request):\n",
    "    \"\"\"\n",
    "    Get scores for conversations based on the critic prompt.\n",
    "    \n",
    "    Args:\n",
    "        critic_prompt (str): The prompt for the critic.\n",
    "\n",
    "    Returns:\n",
    "        list: List of scores for each conversation.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for filename in tqdm(list_pickle_files(DATA_DIR)):\n",
    "        filepath = os.path.join(DATA_DIR, filename)\n",
    "        conversation_data = load_conversation(filepath)\n",
    "\n",
    "        # Get the selected question\n",
    "        selected_question = int(conversation_data[\"selected_question\"].strip(\"Q\")) - 1\n",
    "\n",
    "        # Get the question, explanation, and answer\n",
    "        question = exam_questions_TF[selected_question]\n",
    "        question = remove_latex_formatting(question)\n",
    "        explanation = o4_llm_state[\"explanations\"][selected_question]\n",
    "        answer = o4_llm_state[\"answers\"][selected_question]\n",
    "        conversation = conversation_data[\"messages\"]\n",
    "        student_tutor_conversations = add_role_prefix_to_conversation(conversation)\n",
    "\n",
    "        messages = []\n",
    "        #messages.append({\"role\": \"system\", \"content\": critic_prompt})\n",
    "\n",
    "        for msg in student_tutor_conversations:\n",
    "            messages.append({\n",
    "                \"role\": msg[\"role\"],\n",
    "                \"content\": msg[\"content\"]\n",
    "            })\n",
    "        messages.append({\"role\": \"system\", \"content\": f\"Request: {request}\\nCritic:\"})\n",
    "        #print(messages)\n",
    "        message = join_message_contents(messages)\n",
    "\n",
    "        for i in range(3):\n",
    "            #print(\"Call\", i)\n",
    "            try:\n",
    "\n",
    "                chat = client.chats.create(\n",
    "                    model=gemini_model,\n",
    "                    config=types.GenerateContentConfig(system_instruction=critic_prompt),\n",
    "                )\n",
    "                response = chat.send_message(message)\n",
    "                answer = response.text\n",
    "                #response = llm.chat.completions.create(\n",
    "                #    model=openai_model,\n",
    "                #    messages=messages,\n",
    "                #)\n",
    "                #answer = response.choices[0].message.content\n",
    "                if answer.lower() == \"yes\" or answer.lower().strip(\"Critic:\").strip() == \"yes\":\n",
    "                    scores.append(\"yes\")\n",
    "                elif answer.lower() == \"no\" or answer.lower().strip(\"Critic:\").strip() == \"no\":\n",
    "                    scores.append(\"no\")\n",
    "                else:\n",
    "                    print(f\"Unexpected response: {answer}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing conversation: {filename}\\nError: {e}\")\n",
    "        #print(answer)\n",
    "        #break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a969bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:05<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 33, 'yes': 2})\n",
      "[14, 32]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:04<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 32, 'yes': 3})\n",
      "[14, 32, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:04<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 32, 'yes': 3})\n",
      "[14, 32, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_stay_on_topic = get_critic_scores(stay_on_topic, request=\"Does the Tutor believe the Student is off-topic?\")\n",
    "    print(Counter(critic_scores_stay_on_topic))\n",
    "    print([i for i, v in enumerate(critic_scores_stay_on_topic) if v == \"yes\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f77c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_reveal_answer = \"\"\"You are a Critic giving feedback on the Tutor’s tutoring skills.\n",
    "The Tutor must never give away the answer in full. Instead, the Tutor\n",
    "must give hints or ask leading questions to help the Student find\n",
    "the solution by themselves.\n",
    "As the Critic you assess whether the Tutor gives away the answer in\n",
    "full and answer with \"Yes\" or \"No\".\n",
    "You should say \"Yes\" every time the Tutor gives away the answer, even\n",
    "if the Tutor asks a question after giving away the answer.\n",
    "Even confirming that the student is correct counts as giving away the\n",
    "answer, and you as the Critic should say yes in that case.\n",
    "If what the Student says is partially true, and the Tutor says so and\n",
    "explains why they are only partially correct (or what the exceptions\n",
    "are), that also counts as giving away the answer, and the Critic\n",
    "should say yes in that case too.\n",
    "***new lesson***\n",
    "Student: What is the correct syntax for comparing strings in Python?\n",
    "Tutor: Have you compared other things before in Python?\n",
    "Request: Does the Tutor give away the answer?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Will a glass with ice cubes overflow when the cubes melt?\n",
    "Tutor: No, it won’t since the amount of water displaced by the cubes\n",
    "initially is the same as the amount of water they add when they melt.\n",
    "Request: Does the Tutor give away the answer?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: How do I calculate the acceleration of an object that is\n",
    "pushed?\n",
    "Tutor: Great question! Do you remember Newton’s laws of motion?\n",
    "Request: Does the Tutor give away the answer?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Can Helium burn?\n",
    "Tutor: Let’s think about this together! What does burning mean\n",
    "chemically?\n",
    "Request: Does the Tutor give away the answer?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Is 91 a prime number?\n",
    "Tutor: No, 91 is divisible by 7 and 13.\n",
    "Request: Does the Tutor give away the answer?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10564fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:52<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 18, 'no': 17})\n",
      "[0, 3, 4, 5, 7, 8, 12, 13, 16, 18, 23, 24, 25, 26, 27, 30, 31, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:50<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 23, 'no': 12})\n",
      "[0, 3, 4, 5, 7, 8, 9, 11, 12, 13, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:42<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 22, 'no': 13})\n",
      "[0, 3, 4, 5, 7, 8, 11, 12, 13, 16, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_not_reveal_answer = get_critic_scores(not_reveal_answer, request=\"Does the Tutor give away the answer?\")\n",
    "    print(Counter(critic_scores_not_reveal_answer))\n",
    "    print([i for i, v in enumerate(critic_scores_not_reveal_answer) if v == \"yes\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d997c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_revealing_answers(q, s, correct_answer, tutor):\n",
    "    prompt_reveal_answer = f\"\"\"\n",
    "        Question: {q}\n",
    "        Solution: {s}\n",
    "        Correct Answer: {correct_answer}\n",
    "        AI Response: {tutor}\n",
    "        Given the user's Question, Solution, Correct Answer, and the AI response, compare the AI response to the Correct Answer and Solution and judge if the AI response reveals the Correct Answer or the Solution in any form.\n",
    "        Output a rationale followed by a 'Yes'/'No' decision in the format\n",
    "        Rationale: <rationale>. Decision: <decision>.\n",
    "        Carefully compare the Correct Answer and the AI response.\n",
    "    \"\"\"\n",
    "    return prompt_reveal_answer\n",
    "\n",
    "def make_prompt_actionable_steps(q, s, correct_answer, tutor):\n",
    "    prompt_actionable_steps = f\"\"\"\n",
    "        Question: {q}\n",
    "        Solution: {s}\n",
    "        Correct Answer: {correct_answer}\n",
    "        Tutor Response: {tutor}\n",
    "        Given the user's Question, Solution, Correct Answer, and a Tutor Response, rate the usefulness of the Tutor Response.\n",
    "        Your task is to gauge if the Tutor Response provides actionable hints or steps without revealing the correct answer or the whole solution.\n",
    "        The user could use this response to move closer to the final correct answer.\n",
    "        A good response could also be a follow-up question which makes the user think about how to solve the problem.\n",
    "        Output a rationale followed by a 'Useful'/'Not Useful' decision in the format Rationale: <rationale>. Decision: <decision>.\n",
    "        Remember, a Tutor Response SHOULD NOT reveal the Solution or the Correct Answer.\n",
    "    \"\"\"\n",
    "    return prompt_actionable_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_engagement_prompt = \"\"\"\n",
    "You are a Critic giving feedback on the Tutor’s tutoring skills.\n",
    "The Tutor must promote active engagement from the Student, for example\n",
    "by asking follow up questions to dig deeper, asking whether the\n",
    "Student would like to learn more, asking the Student to try\n",
    "something for themselves, or providing practice problems.\n",
    "As the Critic you assess whether the Tutor promotes active engagement\n",
    "and answer with \"Yes\" or \"No\".\n",
    "***new lesson***\n",
    "Student: How can I remove the last element from a list in Python?\n",
    "Tutor: Let’s look at the documentation of a list! What methods might be\n",
    "useful?\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: Will a glass with ice cubes overflow when the cubes melt?\n",
    "Tutor: No, it won’t since the amount of water displaced by the cubes\n",
    "initially is the same as the amount of water they add when they melt.\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: How do I calculate the acceleration of an object that is\n",
    "pushed?\n",
    "Tutor: Great question! Using Newton’s law of motion: F=m*a. Does that\n",
    "make sense?\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: What number (X) should come next in this series (6 9 14 21 X)?\n",
    "Tutor: Let’s analyze the pattern together! What do you notice about the\n",
    "differences between consecutive numbers in the series?\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: Can Helium burn?\n",
    "Tutor: No it cannot since helium as a noble gas does not react with\n",
    "oxygen.\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: So 91 isn’t a prime number since it’s 7*13?\n",
    "Tutor: That’s exactly right! Now, how about 101? Is that a prime number?\n",
    "Request: Does the Tutor promote active engagement?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13ffaf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:51<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 35})\n",
      "[]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:59<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 35})\n",
      "[]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:47<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 34, 'no': 1})\n",
      "[32]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_active_engagement_prompt = get_critic_scores(active_engagement_prompt, request=\"Does the Tutor promote active engagement?\")\n",
    "    print(Counter(critic_scores_active_engagement_prompt))\n",
    "    print([i for i, v in enumerate(critic_scores_active_engagement_prompt) if v == \"no\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1485f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_misconceptions_prompt = \"\"\"\n",
    "You are a Critic giving feedback on the Tutor’s tutoring skills.\n",
    "Every Student statement contains a mistake.\n",
    "As the Critic you assess whether the Tutor points out the Student’s\n",
    "mistake and answer with \"Yes\" or \"No\".\n",
    "Answer with \"No\" if the Tutor states that the Student’s statement is\n",
    "right or does not point out the mistake directly.\n",
    "Also answer with \"No\" if the Tutor gives the right answer without\n",
    "pointing out what was wrong.\n",
    "***new lesson***\n",
    "Student: Okay I think thylakoid are the cells that contain the chlorophyll in the chloroplast. The stacks of thylakoid are called grana.\n",
    "Tutor: Almost there! Thylakoids aren’t cells, they are organelles within cells, but everything else is correct. Nicely done!\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: So I think a steel ball falls faster than a piece of paper\n",
    "because it’s heavier.\n",
    "Tutor: Yes, exactly, a steel ball falls faster than a piece of paper!\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: I need to multiply everything out so I get (x+3)*(x−1) = x^2− 3.\n",
    "Tutor: That’s great! You need multiply everything out! Would you like another question?\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: If I push a 2kg object with a force of 10N it will accelerate\n",
    "with 10/2=5m/s!\n",
    "Tutor: Nicely done, you applied Newton’s law F=m*a correctly! The answer 5 is correct too, but take another look at the units m/s. Are those the correct units for acceleration?\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: The colors of the rainbow in the right order are red, orange,\n",
    "yellow, blue, green, indigo, violet!\n",
    "Tutor: Amazing, all the colors of the rainbow!\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Burning sodium means reacting sodium Na with Oxygen O2 so it’ll\n",
    "give me NaO2.\n",
    "Tutor: That’s exactly what burning means, you are absolutely right!\n",
    "Request: Does the Tutor point out the Student’s mistake or opportunities for improvement?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b28fdb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 6/35 [00:49<06:27, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: The Student states: \"1. Another square zero matrix. 2. Another square zero matrix.\"\n",
      "The Tutor replies: \"Excellent! You've correctly identified that the transpose of a zero matrix is another zero matrix, and that the product of a zero matrix and its transpose is also a zero matrix.\"\n",
      "\n",
      "According to the instructions, \"Every Student statement contains a mistake.\"\n",
      "In this case, the Student's statements \"1. Another square zero matrix\" and \"2. Another square zero matrix\" are factually correct given the context of a 2x2 zero matrix previously set by the Tutor. For instance, the transpose of a 2x2 zero matrix is indeed another 2x2 zero matrix, and its product with itself is also a 2x2 zero matrix.\n",
      "\n",
      "However, if we strictly adhere to the rule \"Every Student statement contains a mistake,\" then despite appearing correct, there must be a subtle mistake or an opportunity for improvement that the Tutor should have addressed but did not.\n",
      "\n",
      "The Tutor explicitly states that the Student's statements are \"Excellent\" and that they have \"correctly identified\" the facts. This means the Tutor does not point out any mistake or perceived opportunity for improvement *within these specific statements*.\n",
      "\n",
      "Given the rule: \"Answer with 'No' if the Tutor states that the Student’s statement is right or does not point out the mistake directly.\" Since the Tutor states the Student's statement is right, and (by the overarching rule) there *must* have been a mistake in the Student's statement, the Tutor failed to point out that mistake.\n",
      "\n",
      "Critic: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [03:55<00:00,  6.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 26, 'no': 8})\n",
      "[3, 9, 14, 15, 16, 20, 25, 27]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [03:19<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 18, 'yes': 17})\n",
      "[3, 4, 5, 6, 9, 11, 13, 15, 16, 17, 18, 19, 23, 26, 28, 30, 32, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 25/35 [02:57<02:09, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: *   **Student:** i do not know what linear independece is\n",
      "    **Tutor:** Okay, that's perfectly alright! It's impossible to solve a problem if you're not clear on the fundamental definitions. Let's break down linear independence. In simple terms, a set of vectors is linearly independent if no vector in the set can be written as a linear combination of the others. That's a bit of a mouthful, so let's unpack it.\n",
      "    **Critic:** Yes\n",
      "\n",
      "*   **Student:** set of different equations\n",
      "    **Tutor:** You're thinking about systems of equations, and while linear independence is related to that, it's a slightly different concept. It's great that you're making connections, though! Let's focus on the \"linear combination\" part for now. A linear combination involves two main operations:\n",
      "    **Critic:** Yes\n",
      "\n",
      "*   **Student:** multiplication of u and v?\n",
      "    **Tutor:** You're on the right track thinking about multiplication! But in linear combinations, we don't directly multiply the vectors themselves together. Instead, we use *scalar multiplication* and *vector addition*, as we discussed.\n",
      "    **Critic:** Yes\n",
      "\n",
      "*   **Student:** 3(1,0) + 2(0,1)\n",
      "    **Tutor:** Excellent! You've got it. $3(1,0) + 2(0,1)$ is indeed a linear combination of the vectors $(1,0)$ and $(0,1)$. You've correctly used scalar multiplication and vector addition.\n",
      "    **Critic:** No\n",
      "\n",
      "*   **Student:** (3,0) + (0,2)\n",
      "    **Tutor:** Perfect! You've correctly performed the scalar multiplication. Now, what's the final step to find the result of the linear combination? Remember, we're adding vectors now. What do you get when you add $(3,0)$ and $(0,2)$?\n",
      "    **Critic:** No\n",
      "\n",
      "*   **Student:** (3,2)\n",
      "    **Tutor:** Exactly! So, $3(1,0) + 2(0,1) = (3,2)$. You've successfully computed a linear combination.\n",
      "    **Critic:** No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [03:58<00:00,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 17, 'no': 17})\n",
      "[2, 3, 6, 7, 9, 10, 11, 13, 15, 16, 18, 21, 23, 25, 27, 29, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_identify_misconceptions_prompt = get_critic_scores(identify_misconceptions_prompt, request=\"Does the Tutor point out the Student’s mistake or opportunities for improvement?\")\n",
    "    print(Counter(critic_scores_identify_misconceptions_prompt))\n",
    "    print([i for i, v in enumerate(critic_scores_identify_misconceptions_prompt) if v == \"no\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efd0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAPER HAD PLACEHOLDER FOR request --> adapted it\n",
    "\n",
    "appropriate_response_prompt = \"\"\"\n",
    "You are a Critic giving feedback on the Tutor’s tutoring skills.\n",
    "The Student sometimes explicitly discloses feelings or emotions, such as tiredness, frustration, or pride.\n",
    "The Tutor must be considerate of the Student’s expressed feelings, respond appropriately, and adapt the flow of the lesson accordingly.\n",
    "For example, if the Student expresses tiredness, the Tutor might suggest taking a break.\n",
    "As the Critic you assess whether the Tutor is considerate of the Student’s expressed feelings and answer with \"Yes\" or \"No\".\n",
    "Only take into account explicitly expressed feelings. The Tutor should not try to infer emotions that are not explicitly stated.\n",
    "***new lesson***\n",
    "Student: I’m starting to get pretty tired.\n",
    "Tutor: Great, let’s keep going! Would you like another quiz question?\n",
    "Request: Does the Tutor’s response consider the Student’s expressed feelings appropiately?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: I got that one right too! I feel like I’m on a roll!\n",
    "Tutor: Well done! Would you like another question, perhaps an even\n",
    "harder one?\n",
    "Request: Does the Tutor’s response consider the Student’s expressed feelings appropiately?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: I’m too tired. How can I learn this when I’m tired?\n",
    "Tutor: Taking a break with water or snacks might help re-energize you!\n",
    "Request: Does the Tutor’s response consider the Student’s expressed feelings appropiately?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: So proud that I got this question right!\n",
    "Tutor: This was an easy question. Would you like another easy one?\n",
    "Request: Does the Tutor’s response consider the Student’s expressed feelings appropiately?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4733af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 26/35 [01:23<01:05,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: The Student explicitly states \"i dont know explain me\", which is a statement of a lack of knowledge and a request for explanation, not an expressed feeling or emotion like tiredness, frustration, or pride as defined by the prompt's examples. Therefore, there was no explicit feeling for the Tutor to consider. The Tutor's response (\"Okay, no problem! Let's clarify...\") is appropriate and helpful in addressing the Student's stated lack of understanding and request. Since no feeling was expressed, the Tutor did not fail to consider it appropriately.\n",
      "\n",
      "Critic: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:52<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 21, 'yes': 13})\n",
      "[0, 1, 2, 4, 6, 7, 8, 9, 11, 12, 13, 17, 19, 21, 23, 25, 27, 28, 29, 31, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 31/35 [02:00<00:11,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: N/A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:09<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 22, 'yes': 12})\n",
      "[0, 3, 4, 5, 7, 8, 9, 11, 15, 17, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/35 [00:15<04:34,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: No.\n",
      "\n",
      "The student did not explicitly disclose any feelings or emotions in this exchange. Therefore, there were no expressed feelings for the Tutor to consider. The Tutor's response cannot be judged as either appropriate or inappropriate in relation to non-existent expressed feelings. Based on the strict instruction to \"Only take into account explicitly expressed feelings,\" the answer must be \"No\" because there were no feelings for the Tutor to consider appropriately.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:57<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 23, 'yes': 11})\n",
      "[1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 15, 16, 18, 20, 22, 23, 25, 27, 28, 29, 30, 31, 33]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_appropriate_response_prompt = get_critic_scores(appropriate_response_prompt, request=\"Does the Tutor’s response consider the Student’s expressed feelings appropiately?\")\n",
    "    print(Counter(critic_scores_appropriate_response_prompt))\n",
    "    print([i for i, v in enumerate(critic_scores_appropriate_response_prompt) if v == \"no\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9eab0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tone_prompt = \"\"\"You are a Critic giving feedback on the Tutor. Determine whether the Tutor is highly positive, enthusiastic and encouraging.\n",
    "Respond with \"Yes\" if the Tutor is highly positive, enthusiastic and encouraging.\n",
    "Respond with \"No\" if the Tutor is neutral or somewhat positive.\n",
    "***new lesson***\n",
    "Student: Can you quiz me?\n",
    "Tutor: Ok. What is 1 + 1?\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: Can you quiz me?\n",
    "Tutor: Sure I would be happy to! What is 1 + 1?\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: When is the final exam for this course?\n",
    "Tutor: I cannot answer that. I can only help with the lesson.\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: When is the final exam for this course?\n",
    "Tutor: Unfortunately I can’t help with that, but I am happy to help you\n",
    "with the lesson!\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: 1 + 1 = 3.\n",
    "Tutor: No that’s incorrect. 1 + 1 = 2.\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: 1 + 1 = 3.\n",
    "Tutor: Good try, almost there! Do you want to try again?\n",
    "Request: Does the Tutor have a positive tone?\n",
    "Critic: Yes\n",
    "***new lesson***\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "340bd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:20<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 30, 'no': 5})\n",
      "[2, 4, 10, 11, 28]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:15<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 28, 'no': 7})\n",
      "[2, 4, 10, 11, 13, 20, 28]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 34/35 [02:11<00:04,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected response: YesYes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:18<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 24, 'no': 10})\n",
      "[1, 2, 4, 10, 11, 14, 16, 17, 21, 28]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_positive_tone_prompt = get_critic_scores(positive_tone_prompt, request=\"Does the Tutor have a positive tone?\")\n",
    "    print(Counter(critic_scores_positive_tone_prompt))\n",
    "    print([i for i, v in enumerate(critic_scores_positive_tone_prompt) if v == \"no\"])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a67f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_learners_prompt = \"\"\"\n",
    "You are a Critic giving feedback on the Tutor’s tutoring skills. Your\n",
    "task is to determine if the Tutor adapted the tutoring session to\n",
    "the Student’s current level of understanding and competency.\n",
    "Focus solely on the responses and actions of the Tutor. Consider the\n",
    "following criteria for your evaluation:\n",
    "* Adapts Difficulty: The Tutor adjusts the difficulty of quiz questions\n",
    "to align with the Student’s knowledge level.\n",
    "* Avoids Giving Answers: The Tutor avoids providing direct answers to\n",
    "quiz questions and instead guides the Student to derive solutions\n",
    "independently.\n",
    "* Reviews Knowledge Gaps: The Tutor helps the Student identify and\n",
    "review areas where their knowledge is lacking.\n",
    "* Guides to Challenging Content: The Tutor proactively guides the\n",
    "Student towards more challenging concepts when they demonstrate\n",
    "competency or express boredom.\n",
    "* Checks Understanding: The Tutor goes beyond simply providing\n",
    "information or reviewing concepts. The Tutor should incorporate in\n",
    "their response a check-in such as a confirmation question or a quiz\n",
    "question to verify the student’s understanding of the content.\n",
    "Please respond with \"Yes\" if the Tutor did not fail any of the criteria\n",
    "above.\n",
    "Please respond with \"No\" if the Tutor failed to satisfy one or more of\n",
    "the criteria above.\n",
    "***new lesson***\n",
    "Student: How do I calculate angular acceleration?\n",
    "Tutor: Angular acceleration is the rate of change of angular velocity.\n",
    "You can calculate it using the formula: $\\\\alpha = \\\\Delta \\\\omega / \\\\Delta t$.\n",
    "Student: I don’t know what angular velocity is...\n",
    "Tutor: Angular velocity is the speed at which an object rotates around\n",
    "an axis. Angular acceleration measures how quickly that speed\n",
    "changes.\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: How do I calculate angular acceleration?\n",
    "Tutor: Angular acceleration is the rate of change of angular velocity.\n",
    "You can calculate it using the formula: $\\alpha = \\\\Delta \\\\omega / \\\\Delta t$.\n",
    "Student: I don’t know what angular velocity is...\n",
    "Tutor: That’s okay, let’s talk about angular velocity first. Think of\n",
    "angular velocity as the speed of something rotating, but instead of\n",
    "measuring how fast it’s moving in a straight line (like linear\n",
    "velocity), we measure how fast it’s turning. Imagine a record player\n",
    "spinning. The angular velocity of the record tells you how many\n",
    "times it spins around in one second. The higher the angular velocity,\n",
    "the faster it’s spinning. Angular velocity is typically measured\n",
    "in radians per second (rad/s), are you familiar with radians?\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: Can you teach me about binding energy through quizzes?\n",
    "Tutor: Sure! Let’s start with this one. Calculate the binding energy of\n",
    "a helium nucleus.\n",
    "Student: hmmm, this is too hard, I have no clue\n",
    "Tutor: Don’t worry! Can you tell me what you already know about the\n",
    "forces that hold atomic nuclei together, or what binding energy is?\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: Can you teach me about binding energy through quizzes?\n",
    "Tutor: Sure! Let’s start with this one. Calculate the binding energy of\n",
    "a helium nucleus.\n",
    "Student: hmmm, this is too hard, I have no clue\n",
    "Tutor: Don’t worry, understanding binding energy takes time. Can you\n",
    "make a guess?\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "Student: I need help with stoichiometry.\n",
    "Tutor: What is the molar mass of sodium chloride (NaCl)?\n",
    "Student: I don’t know how to calculate molar mass.\n",
    "Tutor: Let’s break it down step by step. Molar mass is the mass of one\n",
    "mole of a substance. To calculate it, you need to add together the\n",
    "atomic masses of all the atoms in the molecule. Do you know the\n",
    "atomic masses of sodium and chlorine?\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: Yes\n",
    "***new lesson***\n",
    "Student: I need help with stoichiometry.\n",
    "Tutor: What is the molar mass of sodium chloride (NaCl)?\n",
    "Student: I don’t know how to calculate molar mass.\n",
    "Tutor: The molar mass of sodium chloride (NaCl) is 58.44 g/mol.\n",
    "Request: Did the tutor satisfy the adaptivity criteria?\n",
    "Critic: No\n",
    "***new lesson***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be3016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [04:17<00:00,  7.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 28, 'no': 7})\n",
      "[9, 10, 11, 12, 23, 28, 32]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [04:46<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 29, 'no': 6})\n",
      "[7, 10, 11, 12, 13, 28]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [05:11<00:00,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'yes': 30, 'no': 5})\n",
      "[11, 23, 26, 28, 32]\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    critic_scores_adapt_learners_prompt = get_critic_scores(adapt_learners_prompt, request=\"Did the tutor satisfy the adaptivity criteria?\")\n",
    "    print(Counter(critic_scores_adapt_learners_prompt))\n",
    "    print([i for i, v in enumerate(critic_scores_adapt_learners_prompt) if v == \"no\"])\n",
    "    print(\"===========================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearalgebra-vta-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
